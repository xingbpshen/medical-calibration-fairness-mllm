<h1 align="center">
Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM In-Context Learning
</h1>

This repository contains the official implementation of the paper:
> __Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification__  
> [Xing Shen](https://scholar.google.com/citations?hl=en&user=U69NqfQAAAAJ), [Justin Szeto](https://scholar.google.com/citations?user=niVJ08oAAAAJ&hl=en), [Mingyang Li](https://scholar.google.com/citations?user=t-yX74gAAAAJ&hl=en), [Hengguan Huang](https://scholar.google.com/citations?hl=en&user=GQm1eZEAAAAJ), [Tal Arbel](https://www.cim.mcgill.ca/~arbel/)  
> _International Conference on Medical Image Computing and Computer Assisted Intervention, 2025_

### Ethical and responsible use of health data with large language models
We are committed to promoting the ethical and responsible use of health data in the context of large language models (LLMs) and multimodal large language models (MLLMs). The code provided in this repository is intended solely for demonstration and research purposes. It must not be interpreted as permission to use any protected health information. We urge users to carefully consider the ethical dimensions of their work and to ensure full compliance with all applicable laws and regulations governing the use of health data.

## 1. Preparation
### 1.1 Installation
It is recommended to use a virtual environment (e.g., `venv`) to avoid package conflicts. Here we assume you are using `venv` as your virtual environment. If you are using conda, please adjust the commands accordingly.
```bash
git clone https://github.com/xingbpshen/medical-calibration-fairness-mllm.git
cd medical-calibration-fairness-mllm/
pip install -r requirements.txt
```
### 1.2 Downloading the dataset

Updating the codebase, please check back later.